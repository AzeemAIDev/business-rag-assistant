{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries for RAG and PDF processing\n",
        "!pip install langchain qdrant_client langchain_huggingface langchain_community pypdf langchain_community langchain-qdrant langchain_openai\n",
        "!pip install -U langchain-qdrant langchain-huggingface"
      ],
      "metadata": {
        "id": "PXN1BBd88mLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Imports -----------------\n",
        "from operator import itemgetter\n",
        "from langchain_qdrant import QdrantVectorStore\n",
        "from langchain_core import embeddings\n",
        "from qdrant_client import QdrantClient\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pypdf import PdfReader  # For reading PDF documents"
      ],
      "metadata": {
        "id": "0ddvD-M89_FF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- PDF Reading -----------------\n",
        "reader = PdfReader(\"\")  # Load PDF\n",
        "print(len(reader.pages))  # Print number of pages in PDF"
      ],
      "metadata": {
        "id": "_afske1H9_6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract text from all pages\n",
        "text = \"\"\n",
        "for page in reader.pages:\n",
        "    text += page.extract_text()"
      ],
      "metadata": {
        "id": "3MpZz6kG-G7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Text Splitting -----------------\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,        # Size of each text chunk\n",
        "    chunk_overlap=15       # Overlap between chunks\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_text(text)\n",
        "print(\"len of the chunks:\", len(chunks))  # Number of chunks created"
      ],
      "metadata": {
        "id": "ePZS3myW-Kqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Embedding Model -----------------\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")  # Sentence embeddings\n",
        "\n",
        "# Metadata for each chunk\n",
        "metadatas = [{\"source\": \"Azeem Tech\", \"page\": i+1} for i in range(len(chunks))]"
      ],
      "metadata": {
        "id": "SiWKC7kb-P2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Qdrant Vector Store -----------------\n",
        "qdrant_url = \"\"           # Qdrant URL\n",
        "qdrant_key = \"\"           # Qdrant API Key\n",
        "collection_name = \"\"      # Collection name in Qdrant"
      ],
      "metadata": {
        "id": "j1oyFlT2-WdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store chunks in Qdrant with embeddings\n",
        "qdrant = QdrantVectorStore.from_texts(\n",
        "    texts=chunks,\n",
        "    embedding=embed_model,\n",
        "    metadatas=metadatas,\n",
        "    url=qdrant_url,\n",
        "    api_key=qdrant_key,\n",
        "    collection_name=collection_name\n",
        ")"
      ],
      "metadata": {
        "id": "9wkk40QI-cuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieve Data From VectorStore\n"
      ],
      "metadata": {
        "id": "-icLfNL0-d0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Qdrant Client -----------------\n",
        "client = QdrantClient(\n",
        "    url=\"\",\n",
        "    api_key=\"\"\n",
        ")\n",
        "print(client.get_collections())  # Verify collections in Qdrant"
      ],
      "metadata": {
        "id": "7QLc6F5g-pxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-initialize vector store for retrieval\n",
        "qdrant = QdrantVectorStore(\n",
        "    client=client,\n",
        "    collection_name=\"\",\n",
        "    embedding=embed_model\n",
        ")\n"
      ],
      "metadata": {
        "id": "2x0Uxh-2-qgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Helper Function -----------------\n",
        "def format_docs(docs):\n",
        "    \"\"\"Combine retrieved documents into single string context\"\"\"\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "UyGTlYKn-uoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Prompt Template -----------------\n",
        "prompt_str = \"\"\"\n",
        "Answer the user in two lines from the following context.\n",
        "context:\n",
        "{context}\n",
        "\n",
        "question:\n",
        "{question}\n",
        "\"\"\"\n",
        "_prompt = ChatPromptTemplate.from_template(prompt_str)\n"
      ],
      "metadata": {
        "id": "EGW09Des-yHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Retriever Setup -----------------\n",
        "num_chunks = 2  # Number of similar chunks to retrieve\n",
        "retriever = qdrant.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwrags={\"k\": num_chunks}  # Typo in original code (should be search_kwargs)\n",
        ")"
      ],
      "metadata": {
        "id": "WCnP45Hf-9AT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- LLM Setup -----------------\n",
        "chat_llm = ChatOpenAI(\n",
        "    model=\"tngtech/deepseek-r1t2-chimera:free\",\n",
        "    openai_api_key=\"sk-xxxx\",  # Replace with environment variable in production\n",
        "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
        "    temperature=0  # Deterministic responses\n",
        ")"
      ],
      "metadata": {
        "id": "xXR40uX1-8ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- RAG Chain Setup -----------------\n",
        "query_fetcher = itemgetter(\"question\")  # Extract question from input\n",
        "\n",
        "setup = {\"question\": query_fetcher,\"context\": query_fetcher | retriever | format_docs}\n",
        "\n",
        "_chain = setup | _prompt | chat_llm  # Complete pipeline"
      ],
      "metadata": {
        "id": "YlEPCIdo-_EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Query & Response -----------------\n",
        "query = \"What is RAG?\"  # Example question\n",
        "response = _chain.invoke({\"question\": query})\n",
        "\n",
        "print(response)  # Print AI assistant response"
      ],
      "metadata": {
        "id": "5iF2BDSy_Cbb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}